{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/torch/lib/python3.8/site-packages/braindecode/datautil/preprocess.py:10: UserWarning: datautil.preprocess module is deprecated and is now under preprocessing.preprocess, please use from import braindecode.preprocessing.preprocess\n",
      "  warn('datautil.preprocess module is deprecated and is now under '\n",
      "/anaconda/envs/torch/lib/python3.8/site-packages/braindecode/datautil/windowers.py:4: UserWarning: datautil.windowers module is deprecated and is now under preprocessing.windowers, please use from import braindecode.preprocessing.windowers\n",
      "  warn('datautil.windowers module is deprecated and is now under '\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets import BaseConcatDataset, BaseDataset\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne.datasets.sleep_physionet.age import fetch_data\n",
    "\n",
    "\n",
    "from braindecode.datautil.preprocess import preprocess, Preprocessor\n",
    "from braindecode.datautil.windowers import create_windows_from_events\n",
    "from braindecode.datautil.preprocess import zscore\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import (\n",
    "    cohen_kappa_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mne\n",
    "from mne.datasets.sleep_physionet.age import fetch_data\n",
    "\n",
    "from braindecode.datautil.preprocess import preprocess, Preprocessor\n",
    "from braindecode.datautil.windowers import create_windows_from_events\n",
    "from braindecode.datautil.preprocess import zscore\n",
    "from braindecode.datasets import BaseConcatDataset, BaseDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "PATH = '/home/likith012/test'\n",
    "\n",
    "\n",
    "# Params\n",
    "NEG_SAMPLES = 128 # number of negative samples per positive sample\n",
    "BATCH_SIZE = 1\n",
    "POS_MIN = 1\n",
    "NEG_MIN = 15\n",
    "EPOCH_LEN = 7\n",
    "NUM_SAMPLES = 2000\n",
    "SUBJECTS = np.arange(6)\n",
    "RECORDINGS = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4001E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4002E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4011E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4012E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4021E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4022E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4031E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4032E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4041E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4042E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4051E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from /home/likith012/test/physionet-sleep-data/SC4052E0-PSG.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 2508000  =      0.000 ... 25080.000 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/torch/lib/python3.8/site-packages/braindecode/preprocessing/preprocess.py:52: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3348000  =      0.000 ... 33480.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3261000  =      0.000 ... 32610.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3447000  =      0.000 ... 34470.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3060000  =      0.000 ... 30600.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3027000  =      0.000 ... 30270.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 2850000  =      0.000 ... 28500.000 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 2706000  =      0.000 ... 27060.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3705000  =      0.000 ... 37050.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3606000  =      0.000 ... 36060.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 2010000  =      0.000 ... 20100.000 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3741000  =      0.000 ... 37410.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up low-pass filter at 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal lowpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 45 samples (0.450 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "837 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 837 events and 3000 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   2 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "1116 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1116 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "1088 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1088 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "1150 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1150 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "1021 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1021 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "1009 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1009 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "951 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 951 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "903 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 903 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "1235 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1235 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "1199 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1199 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "671 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 671 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']\n",
      "Adding metadata with 4 columns\n",
      "Replacing existing metadata with 4 columns\n",
      "1246 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 1246 events and 3000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/torch/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function zscore is deprecated; will be removed in 0.7.0. Use sklearn.preprocessing.scale instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.datasets.base.BaseConcatDataset at 0x7fe1afa4fb50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 1234\n",
    "n_jobs = 1\n",
    "sfreq = 100\n",
    "high_cut_hz = 30\n",
    "\n",
    "window_size_s = 30\n",
    "sfreq = 100\n",
    "window_size_samples = window_size_s * sfreq\n",
    "\n",
    "\n",
    "\n",
    "class SleepPhysionet(BaseConcatDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        subject_ids=None,\n",
    "        recording_ids=None,\n",
    "        preload=False,\n",
    "        load_eeg_only=True,\n",
    "        crop_wake_mins=30,\n",
    "        crop=None,\n",
    "    ):\n",
    "        if subject_ids is None:\n",
    "            subject_ids = range(83)\n",
    "        if recording_ids is None:\n",
    "            recording_ids = [1, 2]\n",
    "\n",
    "        paths = fetch_data(\n",
    "            subject_ids,\n",
    "            recording=recording_ids,\n",
    "            on_missing=\"warn\",\n",
    "            path='/home/likith012/test/',\n",
    "        )\n",
    "\n",
    "        all_base_ds = list()\n",
    "        for p in paths:\n",
    "            raw, desc = self._load_raw(\n",
    "                p[0],\n",
    "                p[1],\n",
    "                preload=preload,\n",
    "                load_eeg_only=load_eeg_only,\n",
    "                crop_wake_mins=crop_wake_mins,\n",
    "                crop=crop,\n",
    "            )\n",
    "            base_ds = BaseDataset(raw, desc)\n",
    "            all_base_ds.append(base_ds)\n",
    "        super().__init__(all_base_ds)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_raw(\n",
    "        raw_fname,\n",
    "        ann_fname,\n",
    "        preload,\n",
    "        load_eeg_only=True,\n",
    "        crop_wake_mins=False,\n",
    "        crop=None,\n",
    "    ):\n",
    "        ch_mapping = {\n",
    "            \"EOG horizontal\": \"eog\",\n",
    "            \"Resp oro-nasal\": \"misc\",\n",
    "            \"EMG submental\": \"misc\",\n",
    "            \"Temp rectal\": \"misc\",\n",
    "            \"Event marker\": \"misc\",\n",
    "        }\n",
    "        exclude = list(ch_mapping.keys()) if load_eeg_only else ()\n",
    "\n",
    "        raw = mne.io.read_raw_edf(raw_fname, preload=preload, exclude=exclude)\n",
    "        annots = mne.read_annotations(ann_fname)\n",
    "        raw.set_annotations(annots, emit_warning=False)\n",
    "\n",
    "        if crop_wake_mins > 0:\n",
    "            # Find first and last sleep stages\n",
    "            mask = [x[-1] in [\"1\", \"2\", \"3\", \"4\", \"R\"] for x in annots.description]\n",
    "            sleep_event_inds = np.where(mask)[0]\n",
    "\n",
    "            # Crop raw\n",
    "            tmin = annots[int(sleep_event_inds[0])][\"onset\"] - crop_wake_mins * 60\n",
    "            tmax = annots[int(sleep_event_inds[-1])][\"onset\"] + crop_wake_mins * 60\n",
    "            raw.crop(tmin=max(tmin, raw.times[0]), tmax=min(tmax, raw.times[-1]))\n",
    "\n",
    "        # Rename EEG channels\n",
    "        ch_names = {i: i.replace(\"EEG \", \"\") for i in raw.ch_names if \"EEG\" in i}\n",
    "        raw.rename_channels(ch_names)\n",
    "\n",
    "        if not load_eeg_only:\n",
    "            raw.set_channel_types(ch_mapping)\n",
    "\n",
    "        if crop is not None:\n",
    "            raw.crop(*crop)\n",
    "\n",
    "        basename = os.path.basename(raw_fname)\n",
    "        subj_nb = int(basename[3:5])\n",
    "        sess_nb = int(basename[5])\n",
    "        desc = pd.Series({\"subject\": subj_nb, \"recording\": sess_nb}, name=\"\")\n",
    "       \n",
    "\n",
    "        return raw, desc\n",
    "\n",
    "\n",
    "random_state = 1234\n",
    "n_jobs = -1\n",
    "sfreq = 100\n",
    "high_cut_hz = 30\n",
    "\n",
    "EPOCH_LEN = 15\n",
    "\n",
    "dataset = SleepPhysionet(\n",
    "    subject_ids=SUBJECTS, recording_ids=RECORDINGS, crop_wake_mins=30\n",
    ")\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(lambda x: x * 1e6),\n",
    "    Preprocessor(\"filter\", l_freq=None, h_freq=high_cut_hz, n_jobs=n_jobs),\n",
    "]\n",
    "\n",
    "# Transform the data\n",
    "preprocess(dataset, preprocessors)\n",
    "\n",
    "\n",
    "mapping = {  # We merge stages 3 and 4 following AASM standards.\n",
    "    \"Sleep stage W\": 0,\n",
    "    \"Sleep stage 1\": 1,\n",
    "    \"Sleep stage 2\": 2,\n",
    "    \"Sleep stage 3\": 3,\n",
    "    \"Sleep stage 4\": 3,\n",
    "    \"Sleep stage R\": 4,\n",
    "}\n",
    "\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset,\n",
    "    trial_start_offset_samples=0,\n",
    "    trial_stop_offset_samples=0,\n",
    "    window_size_samples=window_size_samples,\n",
    "    window_stride_samples=window_size_samples,\n",
    "    preload= True,\n",
    "    mapping=mapping,\n",
    ")\n",
    "\n",
    "\n",
    "preprocess(windows_dataset, [Preprocessor(zscore)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingSampler(Sampler):\n",
    "    def __init__(self, metadata, random_state=None, epoch_len=7):\n",
    "\n",
    "        self.metadata = metadata\n",
    "        self._init_info()\n",
    "        self.rng = check_random_state(random_state)\n",
    "        self.epoch_len = epoch_len\n",
    "\n",
    "    def _init_info(self):\n",
    "        keys = [\"subject\", \"recording\"]\n",
    "\n",
    "        self.metadata = self.metadata.reset_index().rename(\n",
    "            columns={\"index\": \"window_index\"}\n",
    "        )\n",
    "        self.info = (\n",
    "            self.metadata.reset_index()\n",
    "            .groupby(keys)[[\"index\", \"i_start_in_trial\"]]\n",
    "            .agg([\"unique\"])\n",
    "        )\n",
    "        self.info.columns = self.info.columns.get_level_values(0)\n",
    "\n",
    "    def sample_recording(self):\n",
    "        \"\"\"Return a random recording index.\"\"\"\n",
    "        return self.rng.choice(self.n_recordings)\n",
    "\n",
    "    def sample_window(self, rec_ind=None):\n",
    "        \"\"\"Return a specific window.\"\"\"\n",
    "        if rec_ind is None:\n",
    "            rec_ind = self.sample_recording()\n",
    "        win_ind = self.rng.choice(\n",
    "            self.info.iloc[rec_ind][\"index\"][self.epoch_len // 2 : -self.epoch_len // 2]\n",
    "        )\n",
    "        return win_ind, rec_ind\n",
    "\n",
    "    def __iter__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def n_recordings(self):\n",
    "        return self.info.shape[0]\n",
    "\n",
    "\n",
    "class RelativePositioningSampler(RecordingSampler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        metadata,\n",
    "        tau_pos,\n",
    "        tau_neg,\n",
    "        n_examples,\n",
    "        same_rec_neg=True,\n",
    "        random_state=None,\n",
    "        epoch_len=7,\n",
    "        neg_samples = NEG_SAMPLES\n",
    "    ):\n",
    "        super().__init__(metadata, random_state=random_state, epoch_len=epoch_len)\n",
    "\n",
    "        self.tau_pos = tau_pos\n",
    "        self.tau_neg = tau_neg\n",
    "        self.neg_samples = neg_samples\n",
    "        self.n_examples = n_examples\n",
    "        self.same_rec_neg = same_rec_neg\n",
    "\n",
    "    def _sample_pair(self):\n",
    "        \n",
    "        \"\"\"Sample a pair of two windows.\"\"\"\n",
    "        # Sample first window\n",
    "        win_ind1, rec_ind1 = self.sample_window()\n",
    "        \n",
    "        ts1 = self.metadata.iloc[win_ind1][\"i_start_in_trial\"]\n",
    "        ts = self.info.iloc[rec_ind1][\"i_start_in_trial\"]\n",
    "\n",
    "        epoch_min = self.info.iloc[rec_ind1][\"i_start_in_trial\"][self.epoch_len // 2]\n",
    "        epoch_max = self.info.iloc[rec_ind1][\"i_start_in_trial\"][-self.epoch_len // 2]\n",
    "\n",
    "        if self.same_rec_neg:\n",
    "            mask = ((ts <= ts1 - self.tau_neg) & (ts >= epoch_min)) | (\n",
    "                (ts >= ts1 + self.tau_neg) & (ts <= epoch_max)\n",
    "            )\n",
    "\n",
    "        if sum(mask) == 0:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        win_ind2 = []\n",
    "        for i in range(self.neg_samples):\n",
    "            win_ind2.append(self.rng.choice(self.info.iloc[rec_ind1][\"index\"][mask]))\n",
    "        \n",
    "        return win_ind1, win_ind2\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        for i in range(self.n_examples):\n",
    "            yield self._sample_pair()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_examples\n",
    "\n",
    "class RelativePositioningDataset(BaseConcatDataset):\n",
    "    \"\"\"BaseConcatDataset with __getitem__ that expects 2 indices and a target.\"\"\"\n",
    "\n",
    "    def __init__(self, list_of_ds, epoch_len=7):\n",
    "        super().__init__(list_of_ds)\n",
    "        self.return_pair = True\n",
    "        self.epoch_len = epoch_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        pos, neg = index\n",
    "        pos_data = []\n",
    "\n",
    "        for i in range(-(self.epoch_len // 2), self.epoch_len // 2 + 1):\n",
    "            pos_data.append(super().__getitem__(pos + i)[0])\n",
    "\n",
    "        pos_data = np.stack(pos_data, axis=0) # (7, 2, 3000)\n",
    "\n",
    "        \n",
    "        cont_neg_data = []\n",
    "        for idx in neg:\n",
    "            neg_data = []\n",
    "            print(f\"idx: {idx}\")\n",
    "            for i in range(-(self.epoch_len // 2), self.epoch_len // 2 + 1):\n",
    "                neg_data.append(super().__getitem__(idx + i)[0])\n",
    "\n",
    "            neg_data = np.stack(neg_data, axis=0) # (7, 2, 3000)\n",
    "            cont_neg_data.append(neg_data)\n",
    "        cont_neg_data = np.stack(cont_neg_data, axis=0) # (128, 7, 2, 3000)\n",
    "\n",
    "        return pos_data, cont_neg_data\n",
    "\n",
    "class TuneDataset(BaseConcatDataset):\n",
    "    \"\"\"BaseConcatDataset for train and test\"\"\"\n",
    "\n",
    "    def __init__(self, list_of_ds):\n",
    "        super().__init__(list_of_ds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X = super().__getitem__(index)[0]\n",
    "        y = super().__getitem__(index)[1]\n",
    "\n",
    "        return X, y\n",
    "        \n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "subjects = np.unique(windows_dataset.description[\"subject\"])\n",
    "sub_pretext = rng.choice(subjects, 2, replace=False)\n",
    "sub_train = sorted(\n",
    "    rng.choice(sorted(list(set(subjects) - set(sub_pretext))), 2, replace=False)\n",
    ")\n",
    "sub_test = sorted(list(set(subjects) - set(sub_pretext) - set(sub_train)))\n",
    "\n",
    "splitted = dict()\n",
    "splitted[\"pretext\"] = RelativePositioningDataset(\n",
    "    [ds for ds in windows_dataset.datasets if ds.description[\"subject\"] in sub_pretext],\n",
    "    epoch_len = EPOCH_LEN\n",
    ")\n",
    "splitted[\"train\"] = [ds for ds in windows_dataset.datasets if ds.description[\"subject\"] in sub_train]\n",
    "\n",
    "\n",
    "splitted[\"test\"] =    [ds for ds in windows_dataset.datasets if ds.description[\"subject\"] in sub_test]\n",
    "\n",
    "\n",
    "for ds in windows_dataset.datasets:\n",
    "    if ds.description['subject'] in sub_train:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] [0]\n",
      "[0 2] [1]\n",
      "[0 1] [2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
    "\n",
    "for i,(train_idx,val_idx) in enumerate(kfold.split(a)):\n",
    "    # splitted[\"train\"][split] = TuneDataset([splitted[\"train\"][i] for i in train_idx])\n",
    "    # splitted[\"val\"][split] = TuneDataset([splitted[\"train\"][i] for i in val_idx])\n",
    "    print(train_idx, val_idx)\n",
    "    \n",
    "a = [i for k in a for i in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl= TuneDataset(a)\n",
    "cl[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6241,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from augmentations import *\n",
    "from loss import loss_fn\n",
    "from model import sleep_model\n",
    "from train import *\n",
    "from utils import *\n",
    "\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "PATH = '/mnt/scratch/sleepkfoldsame/'\n",
    "\n",
    "# Params\n",
    "SAVE_PATH = \"single-epoch-same.pth\"\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "lr = 5e-4\n",
    "n_epochs = 200\n",
    "NUM_WORKERS = 5\n",
    "N_DIM = 256\n",
    "EPOCH_LEN = 7\n",
    "m = 0.9995\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "random_state = 1234\n",
    "sfreq = 100\n",
    "high_cut_hz = 30\n",
    "\n",
    "# Seeds\n",
    "rng = np.random.RandomState(random_state)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"GPU available: {torch.cuda.device_count()}\")\n",
    "\n",
    "set_random_seeds(seed=random_state, cuda=device == \"cuda\")\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "# Extract number of channels and time steps from dataset\n",
    "n_channels, input_size_samples = (2, 3000)\n",
    "model = sleep_model(n_channels, input_size_samples, n_dim = N_DIM)\n",
    "\n",
    "\n",
    "q_encoder = model.to(device)\n",
    "k_encoder = model.to(device)\n",
    "\n",
    "for param_q, param_k in zip(q_encoder.parameters(), k_encoder.parameters()):\n",
    "    param_k.data.copy_(param_q.data) \n",
    "    param_k.requires_grad = False  # not update by gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for train and test\"\"\"\n",
    "\n",
    "    def __init__(self, subjects):\n",
    "        self.subjects = subjects\n",
    "        self._add_subjects()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X = self.X[index]\n",
    "        y =  self.y[index]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "        \n",
    "    def _add_subjects(self):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for subject in self.subjects:\n",
    "            self.X.append(subject['windows'])\n",
    "            self.y.append(subject['y'])\n",
    "        self.X = np.concatenate(self.X, axis=0)\n",
    "        self.y = np.concatenate(self.y, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"subject\", \"recording\"]\n",
    "\n",
    "metadata1 = splitted[\"train\"].get_metadata()\n",
    "metadata1 = metadata1.reset_index().rename(\n",
    "    columns={\"index\": \"window_index\"}\n",
    ")\n",
    "info1 = (\n",
    "    metadata1.reset_index()\n",
    "    .groupby(keys)[[\"index\", \"i_start_in_trial\"]]\n",
    "    .agg([\"unique\"])\n",
    ")\n",
    "info1.columns = info1.columns.get_level_values(0)\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "rec_ind1 = rng.choice(info1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01.npz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'0'+'1'+'.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"subject\", \"recording\"]\n",
    "\n",
    "metadata = splitted[\"pretext\"].get_metadata()\n",
    "metadata = metadata.reset_index().rename(\n",
    "    columns={\"index\": \"window_index\"}\n",
    ")\n",
    "info = (\n",
    "    metadata.reset_index()\n",
    "    .groupby(keys)[[\"index\", \"i_start_in_trial\"]]\n",
    "    .agg([\"unique\"])\n",
    ")\n",
    "\n",
    "info.columns = info.columns.get_level_values(0)\n",
    "epoch_len = 7\n",
    "rng = np.random.RandomState(1234)\n",
    "rec_ind = rng.choice(info.shape[0])\n",
    "win_ind = rng.choice(\n",
    "        info.iloc[rec_ind][\"index\"][epoch_len // 2 : -epoch_len // 2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>i_start_in_trial</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th>recording</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[2883000, 2886000, 2889000, 2892000, 2895000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[837, 838, 839, 840, 841, 842, 843, 844, 845, ...</td>\n",
       "      <td>[2427000, 2430000, 2433000, 2436000, 2439000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>[1953, 1954, 1955, 1956, 1957, 1958, 1959, 196...</td>\n",
       "      <td>[1974000, 1977000, 1980000, 1983000, 1986000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3041, 3042, 3043, 3044, 3045, 3046, 3047, 304...</td>\n",
       "      <td>[1749000, 1752000, 1755000, 1758000, 1761000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <td>[4191, 4192, 4193, 4194, 4195, 4196, 4197, 419...</td>\n",
       "      <td>[2007000, 2010000, 2013000, 2016000, 2019000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <th>2</th>\n",
       "      <td>[131767, 131768, 131769, 131770, 131771, 13177...</td>\n",
       "      <td>[2412000, 2415000, 2418000, 2421000, 2424000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">80</th>\n",
       "      <th>1</th>\n",
       "      <td>[133086, 133087, 133088, 133089, 133090, 13309...</td>\n",
       "      <td>[2898000, 2901000, 2904000, 2907000, 2910000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[134327, 134328, 134329, 134330, 134331, 13433...</td>\n",
       "      <td>[3042000, 3045000, 3048000, 3051000, 3054000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">81</th>\n",
       "      <th>1</th>\n",
       "      <td>[135555, 135556, 135557, 135558, 135559, 13556...</td>\n",
       "      <td>[1620000, 1623000, 1626000, 1629000, 1632000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[136840, 136841, 136842, 136843, 136844, 13684...</td>\n",
       "      <td>[3063000, 3066000, 3069000, 3072000, 3075000, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               index  \\\n",
       "subject recording                                                      \n",
       "0       1          [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "        2          [837, 838, 839, 840, 841, 842, 843, 844, 845, ...   \n",
       "1       1          [1953, 1954, 1955, 1956, 1957, 1958, 1959, 196...   \n",
       "        2          [3041, 3042, 3043, 3044, 3045, 3046, 3047, 304...   \n",
       "2       1          [4191, 4192, 4193, 4194, 4195, 4196, 4197, 419...   \n",
       "...                                                              ...   \n",
       "77      2          [131767, 131768, 131769, 131770, 131771, 13177...   \n",
       "80      1          [133086, 133087, 133088, 133089, 133090, 13309...   \n",
       "        2          [134327, 134328, 134329, 134330, 134331, 13433...   \n",
       "81      1          [135555, 135556, 135557, 135558, 135559, 13556...   \n",
       "        2          [136840, 136841, 136842, 136843, 136844, 13684...   \n",
       "\n",
       "                                                    i_start_in_trial  \n",
       "subject recording                                                     \n",
       "0       1          [2883000, 2886000, 2889000, 2892000, 2895000, ...  \n",
       "        2          [2427000, 2430000, 2433000, 2436000, 2439000, ...  \n",
       "1       1          [1974000, 1977000, 1980000, 1983000, 1986000, ...  \n",
       "        2          [1749000, 1752000, 1755000, 1758000, 1761000, ...  \n",
       "2       1          [2007000, 2010000, 2013000, 2016000, 2019000, ...  \n",
       "...                                                              ...  \n",
       "77      2          [2412000, 2415000, 2418000, 2421000, 2424000, ...  \n",
       "80      1          [2898000, 2901000, 2904000, 2907000, 2910000, ...  \n",
       "        2          [3042000, 3045000, 3048000, 3051000, 3054000, ...  \n",
       "81      1          [1620000, 1623000, 1626000, 1629000, 1632000, ...  \n",
       "        2          [3063000, 3066000, 3069000, 3072000, 3075000, ...  \n",
       "\n",
       "[113 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               [837, 838, 839, 840, 841, 842, 843, 844, 845, ...\n",
       "i_start_in_trial    [2427000, 2430000, 2433000, 2436000, 2439000, ...\n",
       "Name: (0, 2), dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneDataset(BaseConcatDataset):\n",
    "    \"\"\"BaseConcatDataset for train and test\"\"\"\n",
    "\n",
    "    def __init__(self, list_of_ds):\n",
    "        super().__init__(list_of_ds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X = super().__getitem__(index)[0]\n",
    "        y = super().__getitem__(index)[1]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "splitted[\"train\"] = TuneDataset(\n",
    "    [ds for ds in windows_dataset.datasets if ds.description[\"subject\"] in sub_train]\n",
    ")\n",
    "\n",
    "splitted[\"test\"] = TuneDataset(\n",
    "    [ds for ds in windows_dataset.datasets if ds.description[\"subject\"] in sub_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_window_in_trial</th>\n",
       "      <th>i_start_in_trial</th>\n",
       "      <th>i_stop_in_trial</th>\n",
       "      <th>target</th>\n",
       "      <th>subject</th>\n",
       "      <th>recording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2706000</td>\n",
       "      <td>2709000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2709000</td>\n",
       "      <td>2712000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2712000</td>\n",
       "      <td>2715000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2715000</td>\n",
       "      <td>2718000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2718000</td>\n",
       "      <td>2721000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>53</td>\n",
       "      <td>5991000</td>\n",
       "      <td>5994000</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>54</td>\n",
       "      <td>5994000</td>\n",
       "      <td>5997000</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>55</td>\n",
       "      <td>5997000</td>\n",
       "      <td>6000000</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>56</td>\n",
       "      <td>6000000</td>\n",
       "      <td>6003000</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>57</td>\n",
       "      <td>6000001</td>\n",
       "      <td>6003001</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28418 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      i_window_in_trial  i_start_in_trial  i_stop_in_trial  target  subject  \\\n",
       "0                     0           2706000          2709000       0       12   \n",
       "1                     1           2709000          2712000       0       12   \n",
       "2                     2           2712000          2715000       0       12   \n",
       "3                     3           2715000          2718000       0       12   \n",
       "4                     4           2718000          2721000       0       12   \n",
       "...                 ...               ...              ...     ...      ...   \n",
       "1123                 53           5991000          5994000       0       72   \n",
       "1124                 54           5994000          5997000       0       72   \n",
       "1125                 55           5997000          6000000       0       72   \n",
       "1126                 56           6000000          6003000       0       72   \n",
       "1127                 57           6000001          6003001       0       72   \n",
       "\n",
       "      recording  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "1123          2  \n",
       "1124          2  \n",
       "1125          2  \n",
       "1126          2  \n",
       "1127          2  \n",
       "\n",
       "[28418 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted[\"train\"].get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_window_in_trial</th>\n",
       "      <th>i_start_in_trial</th>\n",
       "      <th>i_stop_in_trial</th>\n",
       "      <th>target</th>\n",
       "      <th>subject</th>\n",
       "      <th>recording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2883000</td>\n",
       "      <td>2886000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2886000</td>\n",
       "      <td>2889000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2889000</td>\n",
       "      <td>2892000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2892000</td>\n",
       "      <td>2895000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2895000</td>\n",
       "      <td>2898000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>55</td>\n",
       "      <td>6603000</td>\n",
       "      <td>6606000</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>56</td>\n",
       "      <td>6606000</td>\n",
       "      <td>6609000</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>57</td>\n",
       "      <td>6609000</td>\n",
       "      <td>6612000</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>58</td>\n",
       "      <td>6612000</td>\n",
       "      <td>6615000</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>59</td>\n",
       "      <td>6612001</td>\n",
       "      <td>6615001</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138023 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      i_window_in_trial  i_start_in_trial  i_stop_in_trial  target  subject  \\\n",
       "0                     0           2883000          2886000       0        0   \n",
       "1                     1           2886000          2889000       0        0   \n",
       "2                     2           2889000          2892000       0        0   \n",
       "3                     3           2892000          2895000       0        0   \n",
       "4                     4           2895000          2898000       0        0   \n",
       "...                 ...               ...              ...     ...      ...   \n",
       "1178                 55           6603000          6606000       0       81   \n",
       "1179                 56           6606000          6609000       0       81   \n",
       "1180                 57           6609000          6612000       0       81   \n",
       "1181                 58           6612000          6615000       0       81   \n",
       "1182                 59           6612001          6615001       0       81   \n",
       "\n",
       "      recording  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "1178          2  \n",
       "1179          2  \n",
       "1180          2  \n",
       "1181          2  \n",
       "1182          2  \n",
       "\n",
       "[138023 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted[\"pretext\"].get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd048391910>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from multi_epoch.utils import CosineAnnealingWarmupRestarts\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18()\n",
    "\n",
    "a = torch.randn((10, 10), requires_grad=True)\n",
    "b = torch.randn((10, 10), requires_grad=True)\n",
    "c = a+b\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = CosineAnnealingWarmupRestarts(optimizer, first_cycle_steps = 500, cycle_mult = 1.2, max_lr = 0.01, min_lr = 5e-6, warmup_steps = 100, gamma = 0.5)\n",
    "\n",
    "step = 0\n",
    "lrs = []\n",
    "\n",
    "for i in range(10000):\n",
    "    step += 1\n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "    \n",
    "plt.plot(lrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subjects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0044ccb47153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subjects' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from data_preprocessing.dataloader import data_generator,cross_data_generator,ft_data_generator\n",
    "from trainer import sleep_ft,sleep_pretrain\n",
    "from config import Config\n",
    "#path = \"/scratch/SLEEP_data/data_multi/sleepEDF/\"\n",
    "path = \"/scratch/SLEEP_data/\"\n",
    "training_mode = 'ss'\n",
    "config = Config()\n",
    "def ft_fun(file_name,epoch):\n",
    "    file_name = file_name+\"_epoch\"+str(epoch)+'.pt'\n",
    "    name = os.path.join(config.exp_path,file_name)\n",
    "    src_path = '/scratch/SLEEP_data/'\n",
    "    n = cross_data_generator(src_path,[],[],config)\n",
    "    kfold = KFold(n_splits=5,shuffle=False)\n",
    "    idxs = np.arange(0,n,1)\n",
    "    for split,(train_idx,val_idx) in enumerate(kfold.split(idxs)):\n",
    "        wandb.init(project='delete',group='K-Cross LE',job_type='split: '+str(split),notes='',name=file_name,save_code=True,entity='sleep-staging')\n",
    "        train_dl,valid_dl= cross_data_generator(src_path,train_idx,val_idx,config)\n",
    "        le_model = sleep_ft(name,config,train_dl,valid_dl,wandb)\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "        le_trainer = pl.Trainer(callbacks=[lr_monitor],profiler='simple',enable_checkpointing=False,max_epochs=config.num_ft_epoch,gpus=1)\n",
    "        wandb.watch([le_model],log='all',log_freq=200)\n",
    "        le_trainer.fit(le_model)\n",
    "        wandb.finish(quiet=True)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--file_name\", type=str, default=\"finv1_fusion_intra\",\n",
    "                    help=\"weights file name\")\n",
    "parser.add_argument(\"--epoch\", type= int, default=20,\n",
    "                    help=\"current epoch\")\n",
    "args = parser.parse_args()\n",
    "ft_fun(args.file_name,int(args.epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_data_generator(data_path,train_idxs,val_idxs,configs):\n",
    "    train_ds = torch.load(os.path.join(data_path, \"train.pt\"))\n",
    "    train_ds['samples'] = train_ds['samples'][:,0,:].unsqueeze(1)\n",
    "    valid_ds = torch.load(os.path.join(data_path, \"val.pt\"))\n",
    "    valid_ds['samples'] = valid_ds['samples'][:,0,:].unsqueeze(1)\n",
    "    train_subs = [48,72,24,30,34,50,38,15,60,12]\n",
    "    train_segs = [3937, 2161, 3448, 1783, 3083, 2429, 3647, 2714, 3392, 2029]\n",
    "    val_subs = [23,26,37,44,49,51,54,59,73,82]\n",
    "    val_segs = [2633, 2577, 2427, 2287, 2141, 2041, 2864, 3071, 4985, 3070]\n",
    "    segs = train_segs+val_segs\n",
    "    if train_idxs !=[]:\n",
    "        dataset = {}\n",
    "        train_dataset = {}\n",
    "        valid_dataset = {}\n",
    "        dataset['samples'] = torch.from_numpy(np.vstack((train_ds['samples'],valid_ds['samples'])))\n",
    "        dataset['labels'] = torch.from_numpy(np.hstack((train_ds['labels'],valid_ds['labels'])))\n",
    "        dataset['samples'] = torch.split(dataset['samples'],segs)\n",
    "        dataset['labels'] = torch.split(dataset['labels'],segs)\n",
    "        print('Split Shape',len(dataset['samples']))\n",
    "        train_dataset['samples'] = [dataset['samples'][i] for i in train_idxs]\n",
    "        train_dataset['labels'] = [dataset['labels'][i] for i in train_idxs]\n",
    "        dataset['samples'] = torch.cat(dataset['samples'])\n",
    "        dataset['labels'] = torch.cat(dataset['labels'])\n",
    "        print('Stack Shape',dataset['samples'].shape,dataset['labels'].shape)\n",
    "        print('Train Shape',train_dataset['samples'].shape,train_dataset['labels'].shape)\n",
    "        train_dataset['samples'] = torch.cat(train_dataset['samples'])\n",
    "        train_dataset['labels'] = torch.cat(train_dataset['labels'])\n",
    "        print('Train Shape',train_dataset['samples'].shape,train_dataset['labels'].shape)\n",
    "        train_dataset = Load_Dataset(train_dataset, configs,data_path=data_path,training_mode='ft')\n",
    "        valid_dataset['samples'] = [dataset['samples'][i] for i in val_idxs]\n",
    "        valid_dataset['labels'] = [dataset['labels'][i] for i in val_idxs]\n",
    "        valid_dataset['samples'] = torch.cat(valid_dataset['samples'])\n",
    "        valid_dataset['labels'] = torch.cat(valid_dataset['labels'])\n",
    "        valid_dataset = Load_Dataset(valid_dataset,configs,data_path=data_path,training_mode='ft')\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=configs.batch_size,\n",
    "                                                   shuffle=True, drop_last=configs.drop_last,\n",
    "                                                   num_workers=10,pin_memory=True,persistent_workers=True)\n",
    "        valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=configs.batch_size,\n",
    "                                                   shuffle=False, drop_last=configs.drop_last,\n",
    "                                                   num_workers=10,pin_memory=True,persistent_workers=True)\n",
    "        del dataset\n",
    "        del train_dataset\n",
    "        del valid_dataset\n",
    "        return train_loader,valid_loader\n",
    "    ret = len(val_subs)+len(train_subs)\n",
    "    del train_ds\n",
    "    del valid_ds\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pretext files: 56500\n",
      "Number of test records: 40\n"
     ]
    }
   ],
   "source": [
    "from braindecode.util import set_random_seeds\n",
    "from multi_epoch.utils import *\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "PATH = '/scratch/sleepkfoldsame/'\n",
    "\n",
    "# Params\n",
    "SAVE_PATH = \"multi-epoch-kfold.pth\"\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "lr = 5e-4\n",
    "n_epochs = 250\n",
    "NUM_WORKERS = 5\n",
    "N_DIM = 128\n",
    "EPOCH_LEN = 7\n",
    "\n",
    "\n",
    "class pretext_data(Dataset):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        \n",
    "        self.file_path = filepath\n",
    "        self.idx = np.array(range(len(self.file_path)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        path = self.file_path[index]\n",
    "        data = np.load(path)\n",
    "        pos = data['pos']\n",
    "        neg = data['neg']\n",
    "        anc = copy.deepcopy(pos)\n",
    "        \n",
    "        for i in range(pos.shape[0]):\n",
    "            pos[i] = augment(pos[i])\n",
    "            anc[i] = augment(anc[i])\n",
    "            neg[i] = augment(neg[i])\n",
    "       \n",
    "        return anc, pos, neg\n",
    "    \n",
    "class train_data(Dataset):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        \n",
    "        self.file_path = filepath\n",
    "        self.idx = np.array(range(len(self.file_path)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        path = self.file_path[index]\n",
    "        data = np.load(path)\n",
    "        \n",
    "        return data['x'], data['y']\n",
    "    \n",
    "    \n",
    "\n",
    "PRETEXT_FILE = os.listdir(os.path.join(PATH, \"pretext\"))\n",
    "PRETEXT_FILE.sort(key=natural_keys)\n",
    "PRETEXT_FILE = [os.path.join(PATH, \"pretext\", f) for f in PRETEXT_FILE]\n",
    "\n",
    "TEST_FILE = os.listdir(os.path.join(PATH, \"test\"))\n",
    "TEST_FILE.sort(key=natural_keys)\n",
    "TEST_FILE = [os.path.join(PATH, \"test\", f) for f in TEST_FILE]\n",
    "\n",
    "print(f'Number of pretext files: {len(PRETEXT_FILE)}')\n",
    "print(f'Number of test records: {len(TEST_FILE)}')\n",
    "\n",
    "pretext_loader = DataLoader(pretext_data(PRETEXT_FILE), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "test_records = [np.load(f) for f in TEST_FILE]\n",
    "test_subjects = dict()\n",
    "\n",
    "for i, rec in enumerate(test_records):\n",
    "    if rec['_description'][0] not in test_subjects.keys():\n",
    "        test_subjects[rec['_description'][0]] = [rec]\n",
    "    else:\n",
    "        test_subjects[rec['_description'][0]].append(rec)\n",
    "\n",
    "test_subjects = list(test_subjects.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([12, 15, 23, 24, 26, 30, 34, 37, 38, 44, 48, 49, 50, 51, 54, 59, 60, 72, 73, 82])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_subjects.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/zombie/multi-epoch/single_epoch_momentum')\n",
    "\n",
    "from augmentations import *\n",
    "from loss import loss_fn\n",
    "from model import sleep_model\n",
    "from train import *\n",
    "from utils import *\n",
    "\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "PATH = '/mnt/scratch/sleepkfoldsame/'\n",
    "\n",
    "# Params\n",
    "SAVE_PATH = \"single-epoch-same.pth\"\n",
    "WEIGHT_DECAY = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "lr = 5e-4\n",
    "n_epochs = 200\n",
    "NUM_WORKERS = 5\n",
    "N_DIM = 256\n",
    "EPOCH_LEN = 7\n",
    "m = 0.9995\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "random_state = 1234\n",
    "sfreq = 100\n",
    "high_cut_hz = 30\n",
    "\n",
    "# Seeds\n",
    "rng = np.random.RandomState(random_state)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"GPU available: {torch.cuda.device_count()}\")\n",
    "\n",
    "set_random_seeds(seed=random_state, cuda=device == \"cuda\")\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "# Extract number of channels and time steps from dataset\n",
    "n_channels, input_size_samples = (2, 3000)\n",
    "model = sleep_model(n_channels, input_size_samples, n_dim = N_DIM)\n",
    "\n",
    "\n",
    "q_encoder = model.to(device)\n",
    "k_encoder = model.to(device)\n",
    "\n",
    "# for param_q, param_k in zip(q_encoder.parameters(), k_encoder.parameters()):\n",
    "#     param_k.data.copy_(param_q.data) \n",
    "#     param_k.requires_grad = False  # not update by gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder(\n",
      "  (model): BaseNet(\n",
      "    (conv1): Conv1d(2, 16, kernel_size=(71,), stride=(2,), padding=(35,), bias=False)\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool1d(kernel_size=71, stride=2, padding=35, dilation=1, ceil_mode=False)\n",
      "    (layer3x3_1): Sequential(\n",
      "      (0): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(8, 8, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv1d(8, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(8, 8, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(8, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(8, 8, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(8, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3x3_2): Sequential(\n",
      "      (0): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(32, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(16, 16, kernel_size=(25,), stride=(2,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv1d(32, 64, kernel_size=(1,), stride=(2,), bias=False)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(16, 16, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(16, 16, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(16, 16, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3x3_3): Sequential(\n",
      "      (0): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(25,), stride=(2,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3x3_4): Sequential(\n",
      "      (0): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(64, 64, kernel_size=(25,), stride=(2,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
      "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(64, 64, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock_Bottle(\n",
      "        (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(64, 64, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
      "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (attention): attention()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for ch in k_encoder.children():\n",
    "   print(ch)\n",
    "   break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1204c25c12f8e04c740b2ed7186598c25c3a2790f80406dfc9c3f371165071bb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
